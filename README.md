# llamacpp-requests
Qwen3-0.6b and llama-server API call only with requests python
